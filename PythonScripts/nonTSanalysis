#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon May 13 11:43:32 2019

@author: carolinadepasquale
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statistics as stat
import scipy.stats as stats
import copy
import random
from math import ceil
import seaborn as sns
from sklearn import preprocessing
from scipy import signal
import scipy.fftpack as fftpack
from statsmodels.tsa.stattools import acf
from statsmodels.graphics import tsaplots
from sklearn.linear_model import LinearRegression
from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import auc
import os
import python_speech_features
import scipy.io
import re
#%% Script import
dir_path = os.path.dirname(os.path.realpath('/Volumes/GoogleDrive/Il mio Drive/Ph.D./PsychologicalSyncStudy/AnalysisScripts/PythonScripts/CleanMain.py'))
os.chdir(dir_path)
import Functions
#%% DATA IMPORTS AND PREPROCESSING

#%%
max_session_n = 17
inFolder = '/Volumes/GoogleDrive/Il mio Drive/Ph.D./PsychologicalSyncStudy/OpenSmileAnalysis/'
outFolder = '/Volumes/GoogleDrive/Il mio Drive/Ph.D./PsychologicalSyncStudy/AnalysisOutput/'
#%% Import all sessions in two dictionaries AUDIO
allPatData = {}
allDocData = {}
for x in range(1,max_session_n):
    try:
        allPatData["session{0}".format(x)] = pd.read_csv(inFolder+'S{0}/S{0}prosody1.csv'.format(x), sep = ';')
        allDocData["session{0}".format(x)] = pd.read_csv(inFolder+"S{0}/S{0}prosody2.csv".format(x), sep = ';')
    except:
        x+1
    print(x)    
#%% Session list
session_list = []
validSessions = []
for x in range(1,max_session_n):
    try:
        allPatData["session{0}".format(x)]
        session_list.append('session{0}'.format(x))
        validSessions.append(x)
    except:
        x+1
    print(x)      
#%% Substitute all 0s with nans only for F0 and remove outliers
cols = ["F0final_sma","voicingFinalUnclipped_sma","pcm_loudness_sma"]

F0Check = 10
F0topQuantile = .95
F0bottomQuantile = .15
topLoud = .95
bottomLoud = .05
allPatData = Functions.removeOutliers(allPatData, cols, F0Check, F0topQuantile, F0bottomQuantile, topLoud, bottomLoud)
allDocData = Functions.removeOutliers(allDocData, cols, F0Check, F0topQuantile, F0bottomQuantile, topLoud, bottomLoud)

#%% Add mel scale to DFs
for x,y in zip(allPatData, allDocData):
    allPatData[x]['melScale'] = python_speech_features.base.hz2mel(allPatData[x]["F0final_sma"])
    allDocData[y]['melScale'] = python_speech_features.base.hz2mel(allDocData[y]["F0final_sma"])
    print(x)
    
#%% Import Anxiety and Empathy scores
empathyScores = pd.read_excel("/Volumes/GoogleDrive/Il mio Drive/Ph.D./PsychologicalSyncStudy/Scores/CC_EUS.xlsx") 
anxietyScore = pd.read_excel("/Volumes/GoogleDrive/Il mio Drive/Ph.D./PsychologicalSyncStudy/Scores/CC_STAI.xlsx")
empathyScores['normPat'] = Functions.normalise(empathyScores['pz'])
empathyScores['normDoc'] = Functions.normalise(empathyScores['ter'])
empathyScores['stdPat'] = Functions.standardise(empathyScores['pz'])
empathyScores['stdDoc'] = Functions.standardise(empathyScores['ter'])
anxietyScore['normScoring'] = Functions.normalise(anxietyScore['scoring'])
anxietyScore['stdScoring'] = Functions.standardise(anxietyScore['scoring'])

empathyScores['session'] = np.zeros(len(empathyScores))
for x in empathyScores['seduta']:
    empathyScores['session'].iloc[x-1] = Functions.rename(str(empathyScores['seduta'].iloc[x-1]), oldname = '{0}', regex = r'\d+')
    print(x)
#%% Select only the sessions I have

validEmpathySessions = empathyScores.loc[empathyScores['seduta'].isin(validSessions)]
validAnxietySessions = anxietyScore.loc[anxietyScore['SEDUTA'].isin(validSessions)]

validEmpathySessions.index = validEmpathySessions['seduta']
validAnxietySessions.index = validAnxietySessions['SEDUTA']
#redundant but future code works on this
validEmpathySessions['sessionName'] = session_list
validAnxietySessions['sessionName'] = session_list
validAnxietySessions['session'] = session_list

#%% Descriptive stats AUDIO
cols = ["F0final_sma","voicingFinalUnclipped_sma","pcm_loudness_sma", 'melScale']
patDescriptiveStats = {}
docDescriptiveStats = {}
for x,y in zip(allPatData, allDocData):
    patDescriptiveStats[x] = Functions.describe_df(allPatData[x], cols)
    docDescriptiveStats[y] = Functions.describe_df(allDocData[y], cols)
    print(x)

#%%create dataframes with all the sessions for descriptive stats. This helps with plotting and modelling
patF0meanIQRstd = Functions.make_df(patDescriptiveStats, 'F0final_sma', 'mean','IQR','std').transpose()
docF0meanIQRstd = Functions.make_df(docDescriptiveStats, 'F0final_sma', 'mean','IQR','std').transpose()
patLoudmeanIQRstd = Functions.make_df(patDescriptiveStats, 'pcm_loudness_sma', 'mean','IQR','std').transpose()
docLoudmeanIQRstd = Functions.make_df(docDescriptiveStats, 'pcm_loudness_sma', 'mean','IQR','std').transpose()
patMelmeanIQRstd = Functions.make_df(patDescriptiveStats, 'melScale', 'mean','IQR','std').transpose()
docMelmeanIQRstd = Functions.make_df(docDescriptiveStats, 'melScale', 'mean','IQR','std').transpose()
patF0meanIQRstd['sessionName'] = session_list
docF0meanIQRstd['sessionName'] = session_list
patLoudmeanIQRstd['sessionName'] = session_list
docLoudmeanIQRstd['sessionName'] = session_list 
patMelmeanIQRstd['sessionName'] = session_list 
docMelmeanIQRstd['sessionName'] = session_list 

#%% Loop to get all correlations I need, and store them in a DF
features = ['F0final_sma','pcm_loudness_sma','melScale']

patGlobal = {}
docGlobal = {}
for f in features:
    patGlobalRaw = {}
    docGlobalRaw = {}
    for x,y in zip(allPatData, allDocData):
        patGlobalRaw[x] = Functions.describe_df(allPatData[x], features)
        docGlobalRaw[y] = Functions.describe_df(allDocData[y], features)
        print(x,f)
    patGlobal[f] = Functions.make_df(patGlobalRaw, f, 'mean','IQR','std').transpose()
    docGlobal[f] = Functions.make_df(docGlobalRaw, f, 'mean','IQR','std').transpose()
    patGlobal[f]['sessionName'] = session_list
    docGlobal[f]['sessionName'] = session_list

#%% correlations
tests = [stats.pearsonr, stats.spearmanr, stats.kendalltau]
statistics = ['mean','IQR','std']
targets = {stats.pearsonr:(validEmpathySessions["stdPat"], validEmpathySessions['stdDoc'],validAnxietySessions['stdScoring']),
           stats.spearmanr:(validEmpathySessions['pz'],validEmpathySessions['ter'],validAnxietySessions['scoring']),
           stats.kendalltau:(validEmpathySessions['pz'],validEmpathySessions['ter'],validAnxietySessions['scoring'])}

patGlobalCorrs = {}

for patdata in patGlobal:
    patGlobalCorrs[patdata] = {}
    for s in statistics:
        patGlobalCorrs[patdata][s] = {}
        for t in targets:
            patGlobalCorrs[patdata][s][t.__name__] = {}
            for series in targets[t]:
                patGlobalCorrs[patdata][s][t.__name__][series.name] = t(patGlobal[patdata][s],series)
                print(series.name, t.__name__, s, patdata)
                
docGlobalCorrs = {}

for docdata in docGlobal:
    docGlobalCorrs[docdata] = {}
    for s in statistics:
        docGlobalCorrs[docdata][s] = {}
        for t in targets:
            docGlobalCorrs[docdata][s][t.__name__] = {}
            for series in targets[t]:
                docGlobalCorrs[docdata][s][t.__name__][series.name] = t(docGlobal[docdata][s],series)
                print(series.name, t.__name__, s, docdata)

patdocCorrsGlob = {}
for docdata in docGlobal:
    patdocCorrsGlob[docdata] = {}
    for s in statistics:
        patdocCorrsGlob[docdata][s] = {}
        for t in tests:
            patdocCorrsGlob[docdata][s][t.__name__] = t(docGlobal[docdata][s],patGlobal[docdata][s])
            print(s, t.__name__, s, docdata)

# item.name -> gives name of objects like series
# item.__name__ -> gives name of function, TWO underscores
#
#%% Vowel space stuff
#%%Corrs Results 
tests = [stats.pearsonr, stats.spearmanr, stats.kendalltau]
statistics = ['mean','IQR','std']
targets = {stats.pearsonr:(validEmpathySessions["stdPat"], validEmpathySessions['stdDoc'],validAnxietySessions['stdScoring']),
           stats.spearmanr:(validEmpathySessions['pz'],validEmpathySessions['ter'],validAnxietySessions['scoring']),
           stats.kendalltau:(validEmpathySessions['pz'],validEmpathySessions['ter'],validAnxietySessions['scoring'])}
data  = pd.DataFrame([patRatios]).T
data.columns = ['ratio']
data['ratio'] = data['ratio'].astype(float)
data['session'] = data.index
index = []
for x in data.index:
    print(x)
    index.append(int(str(data.index[x])[7:]))
patVowelCorr = {}
for score in targets:
    patVowelCorr[score] = {}
    for t in tests:
        print(score,t)
        patVowelCorr[score][t.__name__] = t(data['ratio'],targets[score])
